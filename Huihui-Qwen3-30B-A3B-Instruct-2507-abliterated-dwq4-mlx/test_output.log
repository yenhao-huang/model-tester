===== TEST START 2026-02-21 09:35:19 CST =====
Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]Fetching 14 files:  43%|████▎     | 6/14 [24:13<32:18, 242.30s/it]Fetching 14 files: 100%|██████████| 14/14 [24:13<00:00, 103.84s/it]
Traceback (most recent call last):
  File "<string>", line 13, in <module>
    out1 = mlx_lm.generate(model, tokenizer, prompt=text1, max_tokens=128, temp=0.2, verbose=True)
  File "/Users/yenhaohuang/Desktop/python-venvs/huihui-qwen3-30b/lib/python3.14/site-packages/mlx_lm/generate.py", line 768, in generate
    for response in stream_generate(model, tokenizer, prompt, **kwargs):
                    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yenhaohuang/Desktop/python-venvs/huihui-qwen3-30b/lib/python3.14/site-packages/mlx_lm/generate.py", line 692, in stream_generate
    token_generator = generate_step(prompt, model, **kwargs)
TypeError: generate_step() got an unexpected keyword argument 'temp'
Model loaded in 1460.8s
==========
